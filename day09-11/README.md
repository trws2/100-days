Day 09 to 11:

- Went over the following LLMer [videos](https://www.youtube.com/@LLMer_2025/videos). So far, the best videos to learn LLM for me.
  - 有难度但必读的一篇论文《DeepSeekMath》(SFT and RL can be unified via one equation)
  - 【4】手写 Model py 大模型代码逻辑
  - 【7】Flash Attention 原理讲解
  - 【8】KV Cache 原理讲解
  - 【9】MHA、MQA、GQA各种注意力变种机制讲解
  - 【10】Sparse Attention & Infini Attention 稀疏注意力和无限注意力
  - 【11】Sinusoidal、RoPE、ALiBi等各类位置信息编码
  - 【12】LoRA、QLoRA 讲解 001 【12】LoRA、QLoRA 讲解 
  - LayerNorm层归一化到底做什么的？
  - Transformer里词嵌入+位置信息的深层逻辑
